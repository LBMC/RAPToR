---
title: "`RAPToR` - Building References"
output: 
  rmarkdown::html_document :
    toc: true
    toc_depth: 3
vignette: >
  %\VignetteIndexEntry{RAPToR-refbuilding}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
bibliography: ../inst/REFERENCES.bib
author: Romain Bulteau
date: "`r format(Sys.Date(), '%B %Y')`"
---
  
```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>",
  fig.align = "center",
  out.width = '100%'
)
options(width=100)

gen_figs <- F # whether to generate figures or read from RAPToR-refbuilding_files/figs

figpath <- "../inst/cdoc/RAPToR-refbuilding_figs/"
if(!file.exists(figpath)){
  dir.create(figpath)
}

library(RAPToR)
library(RColorBrewer)
library(beeswarm)

requireNamespace("limma", quietly = T)
requireNamespace("stats")
```

```{r genfig_setup, include = F}
png_custom <- function(figname, path = "", 
                       fig.width = 7, fig.height = 5, res = 150, ...){
  png(filename = paste0(path, figname, ".png"), 
      width = fig.width, height = fig.height, res = res, units = "in")
}

show_fig <- function(figname = knitr::opts_current$get("label"), expr, path = figpath, ...){
  if(gen_figs){
    png_custom(figname = figname, path = figpath, ...)
    eval(expr = expr)
    dev.off()
  }
  else{
    knitr::include_graphics(paste0(path, figname, ".png"))
  }
}

```

```{r load_ds, include=FALSE, eval = gen_figs}
load("../inst/extdata/dsaeschimann2017.RData")
load("../inst/extdata/dshendriks2014.RData")
```

```{r transp_function, echo=F, eval = gen_figs}
transp <- function(col, a=.5){
  colr <- col2rgb(col)
  return(rgb(colr[1,], colr[2,], colr[3,], a*255, maxColorValue = 255))
}
```


# Preamble

This vignette is specifically focused on building references, that are needed to stage samples with `RAPToR`.
For a more general use of the package, [see the `"RAPToR"` vignette](RAPToR.html).


Building references is one of the key aspects of `RAPToR`, as a sample needs an appropriate reference to be staged.
References are broadly usable once built, so they are worth the trouble to set up.

Throughout this vignette, you will see the general workflow of building a reference from the selection of an appropriate dataset, to validating a model for interpolation. 
In the midst of the explanations, examples will be given using the same `dsaeschimann2017` and `dshendriks2014` datasets as in the general usage vignette ( [the code to load these can be found at the end of the vignette](#code-gen_dsaeschimann2017-dshendriks2014) ).

Finally, a few more examples of reference building on different datasets will be included at the end of this document.

I hope this material will cover your reference-building needs. 


# The data

## Selecting / Preparing a dataset

Without a transcriptomic time-series spanning the developmental stages of your samples' organism, I'm afraid there's not much we can do! 
Thankfully, these time-series experiments are (increasingly) numerous in the literature and most model organisms will have some kind of data we can use. 
You may also make (or already have) your own time-series on hand.

### Databases
There are a few databases you can download data from. 
The most well-known are the [Gene Expression Omnibus (GEO)](https://www.ncbi.nlm.nih.gov/geo/) and the [Array Express](https://www.ebi.ac.uk/arrayexpress/).

Both of these databases have APIs to get their data directly from R (*e.g* [the `GEOquery` package](https://bioconductor.org/packages/release/bioc/html/GEOquery.html), as shown in the example dataset loading scripts). 

### What to look out for
Several points of the experimental design should be kept in mind when selecting data for a reference.

   * ***Are there replicates ?*** If so, good. This means you can confirm the dynamics in your data are not noise. I would choose a sparser time-course with replicates over a higher-resolution experiment with one batch to build a reference.
   * ***Is the time point sampling even ?*** Profiling is expensive, so time courses experiments usually account for dynamic ranges of development (*i.e*, early or fast-changing stages are more sampled). For our purpose, we ideally want even sampling (better for spline fitting).  However, if a dataset's sampling respects dynamic ranges, you can still use it for interpolation as-is, or interpolate with a trick using ranks.
   * ***What's the developmental range ?*** The bigger, the better ! (Though as long as the reference spans the age range of samples to stage, it is enough).
   * ***Is the profiling done on whole-organism or dissected parts ?*** You should aim for profiling that matches your sample type. Whole-organism reference for whole-organism samples, dissected tissue/organ reference for similar samples. Dissected tissue (or single-cell) samples are often sparser than whole-organism for biological and technical reasons. To account for this, we recommend to filter out genes with median $log(TPM+1)\lt0.5$ across reference samples. 
   * ***What's the profiling technology ?*** RNAseq is much, *much* cleaner than microarray data, but sometimes you just have to make do. There is no trouble staging RNAseq samples on microarray references and vice-versa. RNAseq counts should have some within-sample normalization (*e.g.* TPM) to reflect gene expression accurately across samples.
   
   
### ID formatting

Bioinformatics is a field plagued by diverse and fast-changing sets of IDs for genes, transcripts, etc.
When you build a reference, you should always convert it to IDs that are **conventional and stable**.
We like to use the organism-specific IDs (*e.g*, Wormbase for *C. elegans* : `WBGene00016153`, Flybase for *Drosophila* : `FBgn0010583`).

The [ensembl biomart](https://www.ensembl.org/info/data/biomart/index.html) or its associated R package [`biomaRt`](https://bioconductor.org/packages/release/bioc/html/biomaRt.html) are a very useful resource to get gene, transcript or probe ID lists for conversion.

Below is a code snippet to get gene IDs for drosophila with `biomaRt`.

```{r biomart_example, eval = F}
requireNamespace("biomaRt", quietly = TRUE)

# setup connection to ensembl
mart <- biomaRt::useMart("ensembl", dataset = "dmelanogaster_gene_ensembl")

# get list of attributes
droso_genes <- biomaRt::getBM(attributes = c("ensembl_gene_id", 
                                             "ensembl_transcript_id",
                                             "external_gene_name",
                                             "flybase_gene_id"),
                              mart = mart)

head(droso_genes)
#>   ensembl_gene_id ensembl_transcript_id external_gene_name flybase_gene_id
#> 1     FBgn0015380           FBtr0330209                drl     FBgn0015380
#> 2     FBgn0015380           FBtr0081195                drl     FBgn0015380
#> 3     FBgn0010356           FBtr0088240               Taf5     FBgn0010356
#> 4     FBgn0266023           FBtr0343232     lncRNA:CR44788     FBgn0266023
#> 5     FBgn0250732           FBtr0091512               gfzf     FBgn0250732
#> 6     FBgn0250732           FBtr0334671               gfzf     FBgn0250732
```

When multiple probe or transcript IDs match a single gene ID, we usually sum-aggregate counts and mean-aggregate other expression values (microarray or already-processed RNAseq as TPMs). 
This is taken care of with the `format_ids()` function.


### Normalize and log expression

It's common practice to normalize expression datasets (*e.g.* to account for technical bias).
You may deal with many different profiling technologies when building references, and may join multiple datasets together for a reference.

To stay as consistent as possible, we apply quantile-normalization on our datasets regardless of source or type.
For this, we use the `normalizeBetweenArrays()` function from [`limma`](https://bioconductor.org/packages/release/bioc/html/limma.html).

We also log-transform the data with $log(X + 1)$.

```{r quantile_norm_log, eval = gen_figs}
dsaeschimann2017$g <- limma::normalizeBetweenArrays(dsaeschimann2017$g, method = "quantile")
dsaeschimann2017$g <- log1p(dsaeschimann2017$g)

dshendriks2014$g <- limma::normalizeBetweenArrays(dshendriks2014$g, method = "quantile")
dshendriks2014$g <- log1p(dshendriks2014$g)
```


## Observing the data

It's good practice to take a look at what's inside your variables before anything else.

```{r obs_head, results='markup', eval=gen_figs}
dsaeschimann2017$g[1:5,1:4]
#>                let.7.n2853._18hr let.7.n2853._20hr let.7.n2853._22hr let.7.n2853._24hr
#> WBGene00007063          7.501850         10.988212          10.45480          7.994587
#> WBGene00007064          8.023767          8.655388          14.21012          9.759401
#> WBGene00007065         15.919452         16.875057          15.23932         18.847718
#> WBGene00003525          1.416181         10.938876          13.42202          2.488798
#> WBGene00007067          1.765342          1.775650           2.77224          2.200257

head(dsaeschimann2017$p, n = 5)
#>                        title geo_accession           organism_ch1       strain
#> GSM2113587 let.7.n2853._18hr    GSM2113587 Caenorhabditis elegans let-7(n2853)
#> GSM2113588 let.7.n2853._20hr    GSM2113588 Caenorhabditis elegans let-7(n2853)
#> GSM2113589 let.7.n2853._22hr    GSM2113589 Caenorhabditis elegans let-7(n2853)
#> GSM2113590 let.7.n2853._24hr    GSM2113590 Caenorhabditis elegans let-7(n2853)
#> GSM2113591 let.7.n2853._26hr    GSM2113591 Caenorhabditis elegans let-7(n2853)
#>            time in development:ch1 age
#> GSM2113587                18 hours  18
#> GSM2113588                20 hours  20
#> GSM2113589                22 hours  22
#> GSM2113590                24 hours  24
#> GSM2113591                26 hours  26
```


### Correlation
With time series data, correlation heatmaps or boxplots of the sample-sample correlation can reveal outliers, and also shows the clear correlation between samples of similar development.

```{r obs_data_corr, eval = gen_figs}
cor_dsaeschimann2017 <- cor(dsaeschimann2017$g, method = "spearman")
```

##### {.tabset}
###### Plots
<div style = "display:block">
<div style="width:40%; float:left">
```{r hm_cor, echo = F, fig.height=5, fig.width=5}
show_fig(expr = {
  ord <- order(dsaeschimann2017$p$age)
  heatmap(cor_dsaeschimann2017[ord, ord], Colv = NA, Rowv = NA, scale = "none", keep.dendro = F, margins = c(1,1),
          RowSideColors = transp(as.numeric(dsaeschimann2017$p$strain[ord])), labRow = "", labCol = "")
  par(xpd = T)
  mtext(text = unique(dsaeschimann2017$p$age), side = 1, line = 4, at = seq(-.1,1.05, l = 11))

}, fig.height=5, fig.width=5)

```
</div>
<div style="width:59%; float:right">
```{r bxplot_cor, echo = F, fig.show='hold', warning=FALSE}
show_fig(expr = {
boxplot(cor_dsaeschimann2017 ~ interaction(dsaeschimann2017$p$strain, dsaeschimann2017$p$age), col = transp(1:4), xaxt = "n", ylab = "Spearman correlation",
        xlab = "age", at = seq(1,44, l = 55)[c(T,T,T,T,F)])
axis(side = 1, at = seq(2,42, l = 11), labels = unique(dsaeschimann2017$p$age))
legend(23,.86, fill = transp(1:4), legend = c("let-7", "lin-41", "let-7/lin-41", "N2"),
       bty = "n")
})
```
</div>
</div>
<div style="clear: both;"></div>

###### Code
```{r hm_bxp_code_print, eval = F}
# Heatmap
ord <- order(dsaeschimann2017$p$age)
heatmap(cor_dsaeschimann2017[ord, ord], Colv = NA, Rowv = NA, scale = "none", keep.dendro = F, margins = c(1,1),
        RowSideColors = as.numeric(dsaeschimann2017$p$strain[ord]), labRow = "", labCol = "")

par(xpd = T) # text may have to be tweaked to plot size
mtext(text = unique(dsaeschimann2017$p$age), side = 1, line = 4, at = seq(-.1,1.05, l = 11)) 

# Boxplot
boxplot(cor_dsaeschimann2017 ~ interaction(dsaeschimann2017$p$strain, dsaeschimann2017$p$age), col = 1:4, xaxt = "n", 
        ylab = "Spearman correlation", xlab = "age", at = seq(1,44, l = 55)[c(T,T,T,T,F)])
axis(side = 1, at = seq(2,42, l = 11), labels = unique(dsaeschimann2017$p$age))

legend(23,.86, fill = 1:4, legend = c("let-7", "lin-41", "let-7/lin-41", "N2"), bty = "n")
```

##### {}


### Plotting components
Plotting components (PCA or ICA) with respect to time is a good way to display general dynamics in the data.
For PCA, we want to perform a non-scaled, centered PCA. 
Centering is done gene-wise, not sample-wise (hence the matrix rotation below).

```{r obs_prcomp, eval = gen_figs}
pca_dsaeschimann2017 <- stats::prcomp(t(dsaeschimann2017$g), rank = 25,
                                      center = TRUE, scale = FALSE)
```

##### {.tabset}
###### Plot
```{r plot_pcadsaeschimann2017, echo = F, fig.height=6, fig.width=12}
show_fig(expr = {
  par(mfrow = c(2,4))
  invisible(sapply(seq_len(8), function(i){
    plot(dsaeschimann2017$p$age, pca_dsaeschimann2017$x[,i], lwd = 2, col = dsaeschimann2017$p$strain,
         xlab = "age", ylab = "PC", main = paste0("PC", i))
    sapply(seq_along(levels(dsaeschimann2017$p$strain)), function(l){
      s <- which(dsaeschimann2017$p$strain == levels(dsaeschimann2017$p$strain)[l])
      points(dsaeschimann2017$p$age[s], pca_dsaeschimann2017$x[s,i], col = l, 
             type = 'l', lty = 2)
    })
    # points(ndat$age, pred_dsaeschimann2017_comp[, i], col = "royalblue", type = 'l', lwd = 2)
    if(i == 1)
      legend("topleft", bty = 'n', legend = c("let-7", "lin-41", "let-7/lin-41", "N2"),
             pch = c(rep(1, 4)), lty = c(rep(NA, 4)), col = c(1:4), lwd = 3)
  }))
}, fig.height=6, fig.width=12)
```

###### Code
```{r plot_pcadsaeschimann2017_print, eval = F}
par(mfrow = c(2,4))
invisible(
sapply(seq_len(8), function(i){
  plot(dsaeschimann2017$p$age, pca_dsaeschimann2017$x[,i], lwd = 2, col = dsaeschimann2017$p$strain,
       xlab = "age", ylab = "PC", main = paste0("PC", i))
  
  # connect the dots
  sapply(seq_along(levels(dsaeschimann2017$p$strain)), function(l){
    s <- which(dsaeschimann2017$p$strain == levels(dsaeschimann2017$p$strain)[l])
    points(dsaeschimann2017$p$age[s], pca_dsaeschimann2017$x[s,i], col = l, 
           type = 'l', lty = 2)
  })

  if(i == 1)
    legend("topleft", bty = 'n', legend = c("let-7", "lin-41", "let-7/lin-41", "N2"),
           pch = c(rep(1, 4)), lty = c(rep(NA, 4)), col = c(1:4), lwd = 3)
})
)
```
##### {}

In this *C. elegans* larval development data, we see very consistent dynamics between different strains. 
Also, PC2 and PC3 capture an oscillatory dynamic which is characteristic of the developmental molts of *C. elegans*.


### Plotting random genes
Another approach is to plot a few random genes, which gives a first hand look at the noise in the data.

##### {.tabset}
###### Plots
```{r plot_rdgn, echo = F, fig.height=3, fig.width=12}
show_fig(expr = {
  set.seed(10)
  gtp <- sample(nrow(dsaeschimann2017$g), size = 4)
  par(mfrow = c(1,4))
  invisible(sapply(gtp, function(i){
    plot(dsaeschimann2017$p$age, dsaeschimann2017$g[i,], lwd = 2, col = dsaeschimann2017$p$strain,
         xlab = "age", ylab = "GExpr", main = rownames(dsaeschimann2017$g)[i])
    sapply(seq_along(levels(dsaeschimann2017$p$strain)), function(l){
      s <- which(dsaeschimann2017$p$strain == levels(dsaeschimann2017$p$strain)[l])
      points(dsaeschimann2017$p$age[s], dsaeschimann2017$g[i,s], col = l, 
             type = 'l', lty = 2)
    })
    # points(ndat$age, pred_dsaeschimann2017_comp[, i], col = "royalblue", type = 'l', lwd = 2)
    if(i == gtp[4])
      legend("topleft", bty = 'n', legend = c("let-7", "lin-41", "let-7/lin-41", "N2"),
             pch = c(rep(1, 4)), lty = c(rep(NA, 4)), col = c(1:4), lwd = 3)
  }))
}, fig.height=3, fig.width=12)
```

###### Code
```{r plot_rdgn_print, eval = F}
set.seed(10) # for reproducibility
gtp <- sample(nrow(dsaeschimann2017$g), size = 4)

par(mfrow = c(1,4))
invisible(
sapply(gtp, function(i){
  plot(dsaeschimann2017$p$age, dsaeschimann2017$g[i,], lwd = 2, col = dsaeschimann2017$p$strain,
       xlab = "age", ylab = "GExpr", main = rownames(dsaeschimann2017$g)[i])
  
  # connect the dots
  sapply(seq_along(levels(dsaeschimann2017$p$strain)), function(l){
    s <- which(dsaeschimann2017$p$strain == levels(dsaeschimann2017$p$strain)[l])
    points(dsaeschimann2017$p$age[s], dsaeschimann2017$g[i,s], col = l, 
           type = 'l', lty = 2)
  })

  if(i == gtp[4])
    legend("topleft", bty = 'n', legend = c("let-7", "lin-41", "let-7/lin-41", "N2"),
           pch = c(rep(1, 4)), lty = c(rep(NA, 4)), col = c(1:4), lwd = 3)
})
)

```

##### {}

<br>
<br>
<br>

# The gene expression interpolation model (GEIM)

Increasing the resolution of a profiling time series is a very unbalanced regression problem.
We want to predict tens of thousands of dependent variables (genes) with a few independent variables (time, batch, ...).


## About the model

In order to model a large number of output variable (genes), our strategy is to project the data in a dimensionally-reduced space and interpolate there before re-projecting the data back to genes.
We do this with Principal Components or Independant Components ( [Independant Component Analysis](https://en.wikipedia.org/wiki/Independent_component_analysis) ).

Both PCA and ICA perform the same type of linear transformation on the data (they just optimize different criteria). We get the following :

$$
X_{(m\times n)} = G_{(m\times c)}S^{T}_{(n\times c)}
$$
with $X$, the matrix of $m$ genes by $n$ samples, $G$ the gene loadings ($m$ genes by $c$ components) and $S^T$ the sample scores ($n$ samples by $c$ components). 
When performing PCA (or ICA) on gene expression data, $S$ is what's usually plotted (e.g. PC1 vs. PC2) to see how samples are grouped in the component space. 
It's what we plotted earlier in the section on observing data, for instance. 

@alter2000singular demonstrated that singular value decomposition of gene expression data can be taken as "eigengenes", giving a global picture of the expression landscape and dynamics with a few components. 
GEIMs use this property.
We fit a model on the columns of $S^T$ (eigengenes), predict in the component space, and reconstruct the gene expression data by a matrix product with the gene loadings. 

We've implemented 2 model types : Generalized Additive Models (GAMs, the default) and Generalized Linear Models (GLMs). 
GAMs rely on the `gam()` function of the [`mgcv`](https://cran.r-project.org/web/packages/mgcv/index.html) package, and GLMs on the `glm()` function of the `stats` core package. 

As you'll see in the next section, a standard R formula will be specified for the model.
This formula can include any tools one can use with `gam()` or `glm()`, most notably the variety of polynomial or smoothing splines implemented through the `s()` function of `mgcv` for GAMs. 
GLMs can also use splines from the `splines` core package, such as `ns()` for natural cubic splines.


## The GEIM interface

Gene Expression Interpolation Models (GEIMs), are built with the `ge_im()` function, which outputs a `geim` object.
This function takes as input 3 key arguments : 

 - `X` : the gene expression matrix of your time-series (genes as rows, samples as columns)
 - `p` : a dataframe of phenotypic data, samples as rows. This should include the age/time variable and any other covariates you want to include in the model (*e.g* batch, strain)
 - `formula` : the model formula. This should be a standard R formula, using terms found in `p`. **It must start with `X ~`**.
 
Another important argument is the **n**umber of **c**omponents to interpolate on, `nc`.

For example, using the `dsaeschimann2017` dataset we could build the following model.
```{r model_dsaeschimann2017, eval = gen_figs}
m_dsaeschimann2017 <- ge_im(X = dsaeschimann2017$g, p = dsaeschimann2017$p, 
                            formula = "X ~ s(age, bs = 'ts') + strain", nc = 32)
```

Note that a single model formula is specified and applied to all the components, but models are fitted independently on the components.

Additional parameters are detailed in the documentation of the function `?ge_im()`.

Model predictions can be generated with the `predict()` function, as for any standard R model.


## Finding the appropriate model and parameters
### Model type
There are 5 types of GEIMs:

* A GAM on PCA components (`method = "gam", dim_red = "pca"`) (default)
* A GLM on PCA components (`method = "glm", dim_red = "pca"`)
* A GAM on ICA components (`method = "gam", dim_red = "ica"`)
* A GLM on ICA components (`method = "glm", dim_red = "ica"`)
* A gene-by-gene linear model directly on the gene expression matrix (`method = "limma"`)

Our default GEIM is fitting GAMs on PCA components, which is a robust choice when applying a smoothing spline to the data.

PCA and ICA interpolation usually yield near-identical results.
ICA tends to outperform PCA when the data is very noisy. 
This is by design, since ICA essentially performs signal extraction.
It is however slower, especially if `nc` is large.

The last option (`"limma"`) corresponds to a solution that makes no effort to reduce the dimensionality of the problem (`dim_red` and `nc` arguments are ignored). 
As a result, there is no information loss or bias introduced by dimension reduction. 
This approach is however very sensitive to noise.
A model is fit with the `lmFit()` function of the `limma` package (hence the option name).


Note that when using GAMs, there can be no interaction between terms (by definition). 
It is possible to include a `by` argument to the `s()` function, which essentially corresponds to separate model fits on each level of the specified group variable (and thus requires enough data to do so).

### Model performance

Model performance can be evaluated through multiple criteria. 
The `mperf()` function computes the indices described below, when given the data and model predictions. 

In the formulas below, $X$ corresponds to the input gene expression matrix ($m$ genes as rows, $n$ samples as columns), $\hat{X}$ to the model predictions. $x_i$ corresponds to row $i$ of matrix $X$ and $x_i^{(j)}$ to sample $j$ of that row. 
This notation is derived from the general regression problem, where $X^T$ corresponds to the set of $m$ dependant variable to predict.

 - `aCC` : average Correlation Coefficient.
 
$$ 
 aCC = \frac{1}{m}\sum^{m}_{i=1}{CC} = \frac{1}{m}\sum^{m}_{i=1}{\cfrac{\sum^{n}_{j=1}{(x_i^{(j)}-\bar{x}_i)(\hat{x}_i^{(j)}-\bar{\hat{x}}_i)}}{\sqrt{\sum^{n}_{j=1}{(x_i^{(j)}-\bar{x}_i)^2(\hat{x}_i^{(j)}-\bar{\hat{x}}_i)^2}}}}
$$

 - `aRE` : average Relative Error. 
 
$$ 
a\delta = \frac{1}{m}\sum^{m}_{i=1}{\delta} = \frac{1}{m} \sum^{m}_{i=1} \frac{1}{n} \sum^{n}_{j=1} \cfrac{| x_i^{(j)} - \hat{x}_i^{(j)} | }{x_i^{(j)}}
$$

 - `MSE` : Mean Squared Error. 

$$ 
MSE = \frac{1}{m} \sum^{m}_{i=1} \frac{1}{n} \sum^{n}_{j=1} (x_i^{(j)} - \hat{x}_i^{(j)} )^2
$$

 - `aRMSE` : average Root MSE.
 
$$ 
aRMSE = \frac{1}{m}\sum^{m}_{i=1}{RMSE} = \frac{1}{m} \sum^{m}_{i=1} \sqrt{\cfrac{\sum^{n}_{j=1} (x_i^{(j)} - \hat{x}_i^{(j)} )^2}{n}}
$$

Note that these indices are computed and averaged *with respect to variables (genes), not observations*. 
`mperf()` outputs either the overall (averaged) index, or values per-gene (`global` parameter).


```{r mperf_dsaeschimann2017, results='markup', eval = gen_figs}
g_mp <- mperf(dsaeschimann2017$g, predict(m_dsaeschimann2017), is.t = T)
g_mp
#> $aCC
#> [1] 0.7977299
#> 
#> $aRE
#> [1] 0.1301014
#> 
#> $MSE
#> [1] 0.01431891
#> 
#> $aRMSE
#> [1] 0.1196617
ng_mp <- mperf(dsaeschimann2017$g, predict(m_dsaeschimann2017), is.t = T, global = F)
ng_mp <- lapply(ng_mp, na.omit) # remove NAs (eg. 0 variance genes)
ng_mp$aRE <- ng_mp$aRE[ng_mp$aRE < Inf] # remove Inf values (/0)
```

It's possible to check the model performance by looking at the index distributions over all genes, *e.g. :*

##### {.tabset}
###### Plots
```{r bxp_mperf_dsaeschimann2017, echo = F, fig.height=5, fig.width=8}
show_fig(expr = {  
  par(mfrow = c(2,2))
  invisible(sapply(names(ng_mp), function(idx){
    rg <- range(na.omit(ng_mp[[idx]]))
    if(idx == "aCC"){
      pos <- 2
    } else {
      pos <- 4
    }
    d <- density(na.omit(ng_mp[[idx]]), from = rg[1], to = rg[2])
    plot(d, main = paste0(gsub("a", "", idx, fixed = T), " density (", length(ng_mp[[idx]]), " genes)"), xlab = idx, lwd = 2)
    abline(v = g_mp[[idx]], lty = 2, lwd = 2, col = "firebrick")
    text(g_mp[[idx]], .9*max(d$y), pos = pos, labels = idx, font = 2, col = "firebrick")
  }))
}, fig.height=5, fig.width=8)
```

###### Code
```{r bxp_mperf_dsaeschimann2017_print, eval = F}
par(mfrow = c(2,2))
invisible(
sapply(names(ng_mp), function(idx){
  rg <- range(na.omit(ng_mp[[idx]]))
  
  # label position
  if(idx == "aCC"){
    pos <- 2
  } else {
    pos <- 4
  }
  # estimate density curve
  d <- density(na.omit(ng_mp[[idx]]), from = rg[1], to = rg[2])
  
  plot(d, main = paste0(gsub("a", "", idx, fixed = T), " density (", length(ng_mp[[idx]]), " genes)"), 
       xlab = idx, lwd = 2)
  # display global value
  abline(v = g_mp[[idx]], lty = 2, lwd = 2, col = "firebrick")
  text(g_mp[[idx]], .9*max(d$y), pos = pos, labels = idx, font = 2, col = "firebrick")
})
)
```

##### {}


### Number of components 

By default, the number of components to interpolate is set to the number of samples.
However, we recommend setting a cutoff on explained variance of PCA (or ICA) components. 

For example, on the `dsaeschimann2017` dataset, we set the threshold at $99\%$ :

```{r nc_dsaeschimann2017, eval=gen_figs}
nc <- sum(summary(pca_dsaeschimann2017)$importance[3,] < .99) + 1
nc
#> [1] 32
```

This threshold must be set in accordance with the noise in the data. 
For example, in very noisy data, would you consider that $99\%$ of the variance in the dataset corresponds to meaningful information ?

You can also define `nc` by plotting your components and stopping after the components stop capturing meaningful variation (dynamics) with respect to time/age. We define components with 'intelligible dynamics' with respect to time as those where a model fit explains $\gt0.5$ of the deviance (noisy components with no dynamics have poor fits).

In very noisy data, you may have to keep very few components ($<5$) for the interpolation.


### Comparing formulas

Choosing from different splines (and/or parameters) can be done with cross-validation (CV).
The `ge_imCV()` function inputs the `X`, `p` and a `formula_list` to test. 
Other parameters on the CV itself can also be given (*e.g.* training set size).

The default training/validation set ratio is `cv.s = 0.8`, so $80\%$ of the data is used to build the model. 
When including (factor) covariates in the model, the training set is built such that all groups are proportionately represented in the training set (based on terms of the first formula in the list).
The number of repeats to do for the CV is defined by `cv.n`.

The model type (GAM/GLM and PCA/ICA) is fixed for all formulas in one call of `ge_imCV()`.

`ge_imCV()` computes the indices of model performance with `mperf()`, excluding `aCC` due to computing time. 
Indices are computed on the validation set (CV Error) *and* on the training set (Model PerFormance).

Below is an example of usage to choose between 4 available GAM smooth terms on the `dsaeschimann2017` GEIM.
```{r include = F, eval = gen_figs}
set.seed(2)
```

```{r cv_dsaeschimann2017, results='markup', eval = gen_figs}
smooth_methods <- c("tp", "ts", "cr", "ps")
flist <- as.list(paste0("X ~ s(age, bs = \'", smooth_methods, "\') + strain"))
flist
#> [[1]]
#> [1] "X ~ s(age, bs = 'tp') + strain"
#> 
#> [[2]]
#> [1] "X ~ s(age, bs = 'ts') + strain"
#> 
#> [[3]]
#> [1] "X ~ s(age, bs = 'cr') + strain"
#> 
#> [[4]]
#> [1] "X ~ s(age, bs = 'ps') + strain"

cv_dsaeschimann2017 <- ge_imCV(X = dsaeschimann2017$g, p = dsaeschimann2017$p, formula_list = flist,
                  cv.n = 20, nc = nc, nb.cores = 3)
#> CV on 4 models. cv.n = 20 | cv.s = 0.8
#> 
#> ...Building training sets
#> ...Setting up cluster
#> ...Running CV
#> ...Cleanup and formatting
```

```{r plot_cv_dsaeschimann2017_show, eval = F}
plot(cv_dsaeschimann2017, names = paste0("bs = ", smooth_methods), outline = F,
     swarmargs = list(cex = .8))
```

```{r plot_cv_dsaeschimann2017, echo = F, fig.width=9, fig.height=8, fig.align='center'}
show_fig(expr = {
  plot(cv_dsaeschimann2017, names = paste0("bs = ", smooth_methods), outline = F,
       swarmargs = list(cex = .8))
}, fig.width=9, fig.height=8)
```

From the plots above, we can see the different splines perform similarly. All could work. 
We chose `ts` (a thin-plate regression spline), as it seems to minimize CV error without much impact on model performance. 


Extra spline parameters can also be specified to the model. 
With `s()`, you can give the spline's basis dimension ($\simeq$ number of knots) to use with the `k` parameter. 
By default, the spline is a *penalized spline*, so it will not necessarily use `k` knots, but it will stay below that value. 
In our experience, the parameter estimation done by `gam()` is usually sufficient and rarely requires tweaking.

By setting `fx = TRUE`, a spline with `k` basis dimension is forced. Note this fits a spline of dimension `k` on *all* components, whereas the penalized spline will adjust. 
The `s()` or `choose.k` documentation gives further information.

Below are examples of spline parameter tweaking with the `dsaeschimann2017` data.

```{r cv_dsaeschimann2017_k, eval = gen_figs}
ks <- c(4,6,8,10)
flistk <- as.list(c(
  "X ~ s(age, bs =  'cr') + strain",
  paste0("X ~ s(age, bs =  'cr', k = ", ks , ") + strain"), 
  paste0("X ~ s(age, bs =  'cr', k = ", ks , ", fx=TRUE) + strain")
  ))
flistk
#> [[1]]
#> [1] "X ~ s(age, bs =  'cr') + strain"
#> 
#> [[2]]
#> [1] "X ~ s(age, bs =  'cr', k = 4) + strain"
#> 
#> [[3]]
#> [1] "X ~ s(age, bs =  'cr', k = 6) + strain"
#> 
#> [[4]]
#> [1] "X ~ s(age, bs =  'cr', k = 8) + strain"
#> 
#> [[5]]
#> [1] "X ~ s(age, bs =  'cr', k = 10) + strain"
#> 
#> [[6]]
#> [1] "X ~ s(age, bs =  'cr', k = 4, fx=TRUE) + strain"
#> 
#> [[7]]
#> [1] "X ~ s(age, bs =  'cr', k = 6, fx=TRUE) + strain"
#> 
#> [[8]]
#> [1] "X ~ s(age, bs =  'cr', k = 8, fx=TRUE) + strain"
#> 
#> [[9]]
#> [1] "X ~ s(age, bs =  'cr', k = 10, fx=TRUE) + strain"

cv_dsaeschimann2017k <- ge_imCV(X = dsaeschimann2017$g, p = dsaeschimann2017$p, formula_list = flistk,
                   cv.n = 20, nc = nc, nb.cores = 3)
#> CV on 9 models. cv.n = 20 | cv.s = 0.8
#> 
#> ...Building training sets
#> ...Setting up cluster
#> ...Running CV
#> ...Cleanup and formatting
```

```{r plot_cv_dsaeschimann2017k, echo = F, fig.width=12, fig.height=9, fig.align='center'}
show_fig(expr = {
  par(mar = c(7,4,3,1))
  plot(cv_dsaeschimann2017k, names = c("na", paste0("k=", ks, rep(c("", ", fx=T"), each = 4))), outline = F,
       col = transp(c("royalblue", rep(c(1, "firebrick"), each = 4))), 
       tcol = c("royalblue", rep(c(1, "firebrick"), each = 4)),
       names.arrange = 5, swarmargs = list(cex = .8))
}, fig.width=12, fig.height=9)
```


## Building a Reference object 

## Building a reference object from a model

A `ref` object can be built from a GEIM using `make_ref()`, specifying interpolation resolution and relevant metadata.

On our `dsaeschimann2017` example :
```{r pred_dsaeschimann2017, eval = gen_figs}
r_dsaeschimann2017 <- make_ref(m = m_dsaeschimann2017,
                               n.inter = 100,                    # interpolation resolution
                               t.unit = "h past egg-laying",     # time unit
                               cov.levels = list("strain" = "N2"), # covariate levels to use for interpolation
                               metadata = list("organism" = "C. elegans", # any metadata
                                               "profiling" = "whole-organism, bulk",
                                               "technology" = "RNAseq")) 

```


As any R model, GEIMs also have a `predict()` function, which can used to manually output predictions either in component space or at the gene level. Doing so manually instead of through `make_ref()` can be useful for a deeper look at the model.

```{r ndat_mdsaeschimann2017, results='markup', eval = gen_figs}
# first generate the new predictor data
n.inter <- 100 # nb of new timepoints
newdat <- data.frame(
  age = seq(min(dsaeschimann2017$p$age), max(dsaeschimann2017$p$age), l = n.inter),
  strain = rep("N2", n.inter) # we want to predict as N2 
  )
head(newdat)
#>        age strain
#> 1 18.00000     N2
#> 2 18.20202     N2
#> 3 18.40404     N2
#> 4 18.60606     N2
#> 5 18.80808     N2
#> 6 19.01010     N2

# predict at gene level
pred_m_dsaeschimann2017 <- predict(m_dsaeschimann2017, newdata = newdat)
# predict at component level
pred_m_dsaeschimann2017_comp <- predict(m_dsaeschimann2017, newdata = newdat, as.c = TRUE)

```

## Validating / Checking model predictions

After building a reference, we can check interpolation results by: 

 - Observing the model predictions against components (plots)
 - Staging the samples on their own interpolated data, or better (if possible) stage another independent time-series on your reference for external validation.


### Checking model predictions against components
Checking predictions against components allows you to immediately see if some dynamics get mishandled by the model. 

Don't hope for perfect fits ! 
It's acceptable to have slight offsets. 

You may also notice some noisy components get "flattened", with a null model fitted. 
These components can be left in or removed as they generally have little to no impact on interpolation at the gene level (representing a minuscule part of total variance in the data). 
This sometimes actually gets rid of unwanted variation.

Plotting a model and a reference object (or equivalent metadata) shows component interpolation, with deviance explained (DE) and relative error (RE) for each component. This information is also returned by the plot function.

Predictions of the first few components from `dsaeschimann2017` are plotted below.

##### {.tabset}
###### Plots
```{r plot_pca_dsaeschimann2017, echo = F, fig.width=12, fig.height=6}
show_fig(expr = {
  par(mfrow = c(2,4))
  invisible(sapply(seq_len(8), function(i){
    suppressWarnings(plot(m_dsaeschimann2017, r_dsaeschimann2017, ncs=i, col.i = 'royalblue',
                          col = dsaeschimann2017$p$strain, show.legend = F))
    if(i == 1)
      legend("topleft", bty = 'n', legend = c("let-7", "lin-41", "let-7/lin-41", "N2", "pred"),
             pch = c(rep(1, 4), NA), lty = c(rep(NA, 4), 1), col = c(1:4, "royalblue"), lwd = 3)
  }))
}, fig.width=12, fig.height=6)
```

###### Code
```{r plot_pca_dsaeschimann2017_print, eval=F}
par(mfrow = c(2,4))
fit_vals <- plot(m_dsaeschimann2017, r_dsaeschimann2017, ncs=1:8, col = dsaeschimann2017$p$strain, col.i = 'royalblue')

head(fit_vals)
#>    component.var.exp        r2 deviance.expl relative.err
#> PC1           0.68673 0.9972253     0.9972253    0.1658575
#> PC2           0.09546 0.9230361     0.9230361    0.3898380
#> PC3           0.08096 0.8783276     0.8783276    1.2464485
#> PC4           0.03242 0.9249808     0.9249808    5.3703222
#> PC5           0.01875 0.8510695     0.8510695    1.6352080
#> PC6           0.01274 0.9249475     0.9249475    2.9281560
```
##### {}
Of note, we are predicting model values as `N2` (lightblue). While all strains are shown on the plots above, some model parameters depend on the selected `N2` strain. 


The interpolation should translate well on the full expression matrix :

##### {.tabset}
###### Plots
```{r plot_rd_genes_pred, echo = F, fig.height = 3, fig.width=12}
show_fig(expr = {
  par(mfrow = c(1,4))
  invisible(sapply(gtp, function(i){
    plot(dsaeschimann2017$p$age, dsaeschimann2017$g[i,], lwd = 2, col = dsaeschimann2017$p$strain,
         xlab = "age", ylab = "GExpr", main = rownames(dsaeschimann2017$g)[i])
    sapply(seq_along(levels(dsaeschimann2017$p$strain)), function(l){
      s <- which(dsaeschimann2017$p$strain == levels(dsaeschimann2017$p$strain)[l])
      points(dsaeschimann2017$p$age[s], dsaeschimann2017$g[i,s], col = l, 
             type = 'l', lty = 2)
    })
    points(r_dsaeschimann2017$time, r_dsaeschimann2017$interpGE[i, ], col = "royalblue", type = 'l', lwd = 3)
    if(i == gtp[4])
      legend("topleft", bty = 'n', legend = c("let-7", "lin-41", "let-7/lin-41", "N2"),
             pch = c(rep(1, 4)), lty = c(rep(NA, 4)), col = c(1:4), lwd = 3)
  }))
}, fig.height = 3, fig.width=12)
```

###### Code
```{r plot_rd_genes_pred_print, eval = F}
par(mfrow = c(1,4))
invisible(
sapply(gtp, function(i){ # gtp is from the earlier random ^gene plots
  plot(dsaeschimann2017$p$age, dsaeschimann2017$g[i,], lwd = 2, col = dsaeschimann2017$p$strain,
       xlab = "age", ylab = "GExpr", main = rownames(dsaeschimann2017$g)[i])
  
  # connect the dots
  sapply(seq_along(levels(dsaeschimann2017$p$strain)), function(l){
    s <- which(dsaeschimann2017$p$strain == levels(dsaeschimann2017$p$strain)[l])
    points(dsaeschimann2017$p$age[s], dsaeschimann2017$g[i,s], col = l, 
           type = 'l', lty = 2)
  })
  
  # add model prediction
  points(r_dsaeschimann2017$time, r_dsaeschimann2017$interpGE[i, ], col = "royalblue", type = 'l', lwd = 3)
  
  if(i == gtp[4])
    legend("topleft", bty = 'n', legend = c("let-7", "lin-41", "let-7/lin-41", "N2"),
           pch = c(rep(1, 4)), lty = c(rep(NA, 4)), col = c(1:4), lwd = 3)
})
)
```
##### {}


### Staging samples

Staging the samples used to build the reference on their interpolated version is a good first test.

Then, staging another time-series from the literature on your reference is the best validation, if such data exists.
This external validation confirms the interpolated dynamics indeed correspond to development processes and not a dataset-specific effect (which is unlikely, but not impossible).

For our example, we can use the `dshendriks2014` dataset for external validation.

```{r ae_dsaeschimann2017_test_print, eval = F}
ae_test_dsaeschimann2017 <- ae(dsaeschimann2017$g, r_dsaeschimann2017)
ae_test_dshendriks2014 <- ae(dshendriks2014$g, r_dsaeschimann2017)
```

```{r ae_dsaeschimann2017_test, include = F, eval = gen_figs}
ae_test_dsaeschimann2017 <- ae(dsaeschimann2017$g, r_dsaeschimann2017, bootstrap.n = 1)
ae_test_dshendriks2014 <- ae(dshendriks2014$g, r_dsaeschimann2017, bootstrap.n = 1)
```

##### {.tabset}
###### Plots
```{r ae_vs_est_plot, echo=F, fig.height=6, fig.width=12}
show_fig(expr = {
  par(mfrow = c(1,2))
  rg <- range(c(ae_test_dsaeschimann2017$age.estimates[,1], dsaeschimann2017$p$age))
  plot(ae_test_dsaeschimann2017$age.estimates[,1]~dsaeschimann2017$p$age, 
       xlab = "Chronological age", ylab = "Estimated age (dsaeschimann2017)", 
       xlim = rg, ylim = rg,
       main = "Chron. vs Estimated ages for dsaeschimann2017\n(on dsaeschimann2017 reference)", lwd = 2, col = factor(dsaeschimann2017$p$strain))
  invisible(sapply(levels(factor(dsaeschimann2017$p$strain)), function(l){
    s <- dsaeschimann2017$p$strain == l
    points(ae_test_dsaeschimann2017$age.estimates[s,1]~dsaeschimann2017$p$age[s], type = 'l', 
           lty = 2, col = which(l==levels(factor(dsaeschimann2017$p$strain))))
  }))
  
  abline(a = 0, b = 1, lty = 3, lwd = 2)
  legend("bottomright", legend = c("let-7", "lin-41", "let-7/lin-41", "N2", "x = y"), 
         lwd=3, col=c(1:4, 1), bty='n', pch = c(1,1,1,1,NA), lty = c(rep(NA, 4), 3))
  
  rg <- range(c(ae_test_dshendriks2014$age.estimates[,1], dshendriks2014$p$age))
  plot(ae_test_dshendriks2014$age.estimates[,1]~dshendriks2014$p$age, 
       xlab = "Chronological age", ylab = "Estimated age (dsaeschimann2017)", 
       xlim = rg, ylim = rg,
       main = "Chron. vs Estimated ages for dshendriks2014\n(on dsaeschimann2017 reference)", lwd = 2)
  points(ae_test_dshendriks2014$age.estimates[,1] ~ dshendriks2014$p$age, type = 'l', lty = 2)
  abline(a = 0, b = 1, lty = 3, lwd = 2)
  
  legend("bottomright", legend = "x = y", lwd=3, col=1, lty = 3, bty='n')
}, fig.height=6, fig.width=12)
```

###### Code
```{r ae_vs_est_plot_print, eval=F}
par(mfrow = c(1,2))
rg <- range(c(ae_test_dsaeschimann2017$age.estimates[,1], dsaeschimann2017$p$age))

# Plot 1
plot(ae_test_dsaeschimann2017$age.estimates[,1]~dsaeschimann2017$p$age, 
     xlab = "Chronological age", ylab = "Estimated age (dsaeschimann2017)", 
     xlim = rg, ylim = rg,
     main = "Chron. vs Estimated ages for dsaeschimann2017\n(on dsaeschimann2017 reference)", lwd = 2, 
     col = factor(dsaeschimann2017$p$strain))
# connect the dots
invisible(sapply(levels(factor(dsaeschimann2017$p$strain)), function(l){
  s <- dsaeschimann2017$p$strain == l
  points(ae_test_dsaeschimann2017$age.estimates[s,1]~dsaeschimann2017$p$age[s], type = 'l', 
         lty = 2, col = which(l==levels(factor(dsaeschimann2017$p$strain))))
}))
abline(a = 0, b = 1, lty = 3, lwd = 2) # x = y

legend("bottomright", legend = c("let-7", "lin-41", "let-7/lin-41", "N2", "x = y"), 
       lwd=3, col=c(1:4, 1), bty='n', pch = c(1,1,1,1,NA), lty = c(rep(NA, 4), 3))


# Plot 2
rg <- range(c(ae_test_dshendriks2014$age.estimates[,1], dshendriks2014$p$age))
plot(ae_test_dshendriks2014$age.estimates[,1]~dshendriks2014$p$age, 
     xlab = "Chronological age", ylab = "Estimated age (dsaeschimann2017)", 
     xlim = rg, ylim = rg,
     main = "Chron. vs Estimated ages for dshendriks2014\n(on dsaeschimann2017 reference)", lwd = 2)
# connect the dots
points(ae_test_dshendriks2014$age.estimates[,1] ~ dshendriks2014$p$age, type = 'l', lty = 2)
abline(a = 0, b = 1, lty = 3, lwd = 2) # x = y

legend("bottomright", legend = "x = y", lwd=3, col=1, lty = 3, bty='n')
```
##### {}
<br>

# Reference-Building examples

Here you will find a few examples of reference building on different organisms.

 - [*C. elegans* larval development](#ex-1) (used in the vignette above)
 - [*D. melanogaster* embryonic development](#ex-2) 
 - [*Danio rerio* embryonic development](#ex-3)

<br>
<br>
<a name="ex-1"></a>


## *C. elegans* larval development
```{r ex_1, child = "ex_1.Rmd"}

```

<br>
<br>
<a name="ex-2"></a>

## *D. melanogaster* embryonic development
```{r ex_2, child = "ex_2.Rmd"}

```


<br>
<br>
<a name="ex-3"></a>

## *Danio rerio* embryonic development
```{r ex_3, child = "ex_3.Rmd"}

```

<a href="#top">Back to top</a>

<hr>

# References