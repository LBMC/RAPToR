---
title: "`RAPToR` - Building References"
output: 
  rmarkdown::html_document :
    toc: true
    toc_depth: 3
vignette: >
  %\VignetteIndexEntry{RAPToR-refbuilding}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
bibliography: ../inst/REFERENCES.bib
author: Romain Bulteau
date: "`r format(Sys.Date(), '%B %Y')`"
---
  
```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>",
  fig.align = "center",
  out.width = '100%'
)
options(width=100)

gen_figs <- F # whether to generate figures or read from RAPToR-refbuilding_files/figs

figpath <- "../inst/cdoc/RAPToR-refbuilding_figs/"
if(!file.exists(figpath)){
  dir.create(figpath)
}

library(RAPToR)
library(RColorBrewer)
library(beeswarm)

requireNamespace("limma", quietly = T)
requireNamespace("stats")
```

```{r genfig_setup, include = F}
png_custom <- function(figname, path = "", 
                       fig.width = 7, fig.height = 5, res = 150, ...){
  png(filename = paste0(path, figname, ".png"), 
      width = fig.width, height = fig.height, res = res, units = "in")
}

show_fig <- function(figname = knitr::opts_current$get("label"), expr, path = figpath, ...){
  if(gen_figs){
    png_custom(figname = figname, path = figpath, ...)
    eval(expr = expr)
    dev.off()
  }
  else{
    knitr::include_graphics(paste0(path, figname, ".png"))
  }
}

```

```{r load_ds, include=FALSE, eval = gen_figs}
load("../inst/extdata/dsaeschimann2017.RData")
load("../inst/extdata/dshendriks2014.RData")
```

```{r transp_function, echo=F, eval = gen_figs}
transp <- function(col, a=.5){
  colr <- col2rgb(col)
  return(rgb(colr[1,], colr[2,], colr[3,], a*255, maxColorValue = 255))
}
```


# Preamble

This vignette is specifically focused on building references needed to stage samples with `RAPToR`.
For a more general use of the package, [see the `"RAPToR"` vignette](RAPToR.html).


Building references is one of the key aspects of `RAPToR`. 
An appropriate reference is needed to stage samples, and since they are re-usable we believe they are worth the trouble to set up.

Throughout this vignette, you will see the general workflow of building a reference from the selection of an appropriate dataset, to choosing and validating a model for interpolation. 
In the midst of the explanations, examples will be given using the same `dsaeschimann2017` and `dshendriks2014` datasets as in the general usage vignette ( [you can check out how these were built at the end of the vignette](#code-gen_dsaeschimann2017-dshendriks2014) ).

Finally, a few more examples of reference building on different datasets will be included at the end of this document.

I hope this material will be sufficient for your reference-building needs. 


# The data

## Selecting / Preparing a dataset

Without a transcriptomic timecourse dataset spanning the developmental stages of your samples' organism, I'm afraid there's not much we can do for you ! 
Thankfully, these time-series experiments are (increasingly) numerous in the literature and most model organisms will have some kind of dataset we can use. 
You may also have your own time-series data on hand.

### Databases
There are a few databases you can download datasets from. 
The most well-known the [Gene Expression Omnibus (GEO)](https://www.ncbi.nlm.nih.gov/geo/) and the [Array Express](https://www.ebi.ac.uk/arrayexpress/).

Both of these databases have APIs to get their data from R (*e.g* [the `GEOquery` package](https://bioconductor.org/packages/release/bioc/html/GEOquery.html), as shown in the example dataset loading scripts).

### What to look out for
Several points of the experimental design should be kept in mind when selecting a dataset for a reference.

   * ***Are there replicates ?*** If so, good. This means you can confirm the dynamics in your data are not noise. I would choose a sparser time-course with replicates over a higher-resolution experiment with one batch to build a reference.
   * ***Is the timepoint sampling even ?*** Transcriptomic profiling is expensive. Time courses experiments usually account for dynamic ranges of development (*i.e*, early or fast-changing stages are more sampled). For our purpose, we ideally want even sampling.  However, if a dataset's sampling respects dynamic ranges, you can still use it for reference building with a trick using ranks.
   * ***What's the developmental range ?*** The bigger, the better ! (Though as long as the samples to stage fit within, it is enough).
   * ***Is the profiling done on whole-organism or specific parts ?*** You should aim for whole-organism profiling. Even if you have to stage tissue-specific samples, a good quality reference should still allow you to get accurate estimates, perhaps restraining the geneset used for staging.
   * ***What's the profiling technology*** RNA-seq is much, *much* cleaner than MicroArray data. Sometimes, you just have to make do. When using RNA-seq counts, apply some within-sample normalization (*e.g.* TPM) to reflect gene expression accurately.
   
   
### ID formatting

One of the plagues of bioinformatics is the large and fast-changing set of IDs for genes, transcripts, etc.
When you build a reference, you should always convert it to IDs that are **conventional and stable**.
We like to use the organism-specific IDs (*e.g*, Wormbase for *C. elegans* : `WBGene00016153`, Flybase for *Drosophila* : `FBgn0010583`).

The [ensembl biomart](https://www.ensembl.org/info/data/biomart/index.html) or its associated R package [`biomaRt`](https://bioconductor.org/packages/release/bioc/html/biomaRt.html) are a very useful ressource to get gene, transcript or probe ID lists for conversion.

Below is a code snippet with an example getting gene IDs for drosophila with `biomaRt`.

```{r biomart_example, eval = F}
requireNamespace("biomaRt", quietly = TRUE)

# setup connection to ensembl
mart <- biomaRt::useMart("ensembl", dataset = "dmelanogaster_gene_ensembl")

# get list of attributes
droso_genes <- biomaRt::getBM(attributes = c("ensembl_gene_id", 
                                             "ensembl_transcript_id",
                                             "external_gene_name",
                                             "flybase_gene_id"),
                              mart = mart)

head(droso_genes)
#>   ensembl_gene_id ensembl_transcript_id external_gene_name flybase_gene_id
#> 1     FBgn0053882           FBtr0091886      His2B:CG33882     FBgn0053882
#> 2     FBgn0035648           FBtr0113148            CG13288     FBgn0035648
#> 3     FBgn0035648           FBtr0331563            CG13288     FBgn0035648
#> 4     FBgn0032726           FBtr0342927            CG10621     FBgn0032726
#> 5     FBgn0032726           FBtr0342926            CG10621     FBgn0032726
#> 6     FBgn0032726           FBtr0081191            CG10621     FBgn0032726
```

When multiple probe or transcript IDs match a single gene ID, we usually go for mean-aggregation of expression values. 
This is taken care of with the `format_ids()` function.


### Normalize and log expression

It's common practice to normalize expression datasets (*e.g.* to account for technical bias).
You may deal with many different profiling technologies when building references, and may join multiple datasets together for a reference.

To stay as consistent as possible, we apply quantile-normalization on our datasets regardless of its source.
For this, we use the `normalizeBetweenArrays()` function of the [`limma`](https://bioconductor.org/packages/release/bioc/html/limma.html) package.

We also apply a $log(X + 1)$.

```{r quantile_norm_log, eval = gen_figs}
dsaeschimann2017$g <- limma::normalizeBetweenArrays(dsaeschimann2017$g, method = "quantile")
dsaeschimann2017$g <- log1p(dsaeschimann2017$g)

dshendriks2014$g <- limma::normalizeBetweenArrays(dshendriks2014$g, method = "quantile")
dshendriks2014$g <- log1p(dshendriks2014$g)
```


## Observing the data

It's usually a good practice to take a look at what's inside your data before doing anything else to it.

```{r obs_head, results='markup', eval=gen_figs}
dsaeschimann2017$g[1:5,1:4]
#>                let.7.n2853._18hr let.7.n2853._20hr let.7.n2853._22hr let.7.n2853._24hr
#> WBGene00007063          7.501850         10.988212          10.45480          7.994587
#> WBGene00007064          8.023767          8.655388          14.21012          9.759401
#> WBGene00007065         15.919452         16.875057          15.23932         18.847718
#> WBGene00003525          1.416181         10.938876          13.42202          2.488798
#> WBGene00007067          1.765342          1.775650           2.77224          2.200257

head(dsaeschimann2017$p, n = 5)
#>                        title geo_accession           organism_ch1       strain
#> GSM2113587 let.7.n2853._18hr    GSM2113587 Caenorhabditis elegans let-7(n2853)
#> GSM2113588 let.7.n2853._20hr    GSM2113588 Caenorhabditis elegans let-7(n2853)
#> GSM2113589 let.7.n2853._22hr    GSM2113589 Caenorhabditis elegans let-7(n2853)
#> GSM2113590 let.7.n2853._24hr    GSM2113590 Caenorhabditis elegans let-7(n2853)
#> GSM2113591 let.7.n2853._26hr    GSM2113591 Caenorhabditis elegans let-7(n2853)
#>            time in development:ch1 age
#> GSM2113587                18 hours  18
#> GSM2113588                20 hours  20
#> GSM2113589                22 hours  22
#> GSM2113590                24 hours  24
#> GSM2113591                26 hours  26
```


### Correlation
With our time series data, we can look at correlation heatmaps or boxplots of the samples to catch potential ouliers and observe the clear correlation between samples of similar development.

```{r obs_data_corr, eval = gen_figs}
cor_dsaeschimann2017 <- cor(dsaeschimann2017$g, method = "spearman")
```

##### {.tabset}
###### Plots
<div style = "display:block">
<div style="width:40%; float:left">
```{r hm_cor, echo = F, fig.height=5, fig.width=5}
show_fig(expr = {
  ord <- order(dsaeschimann2017$p$age)
  heatmap(cor_dsaeschimann2017[ord, ord], Colv = NA, Rowv = NA, scale = "none", keep.dendro = F, margins = c(1,1),
          RowSideColors = transp(as.numeric(dsaeschimann2017$p$strain[ord])), labRow = "", labCol = "")
  par(xpd = T)
  mtext(text = unique(dsaeschimann2017$p$age), side = 1, line = 4, at = seq(-.1,1.05, l = 11))

}, fig.height=5, fig.width=5)

```
</div>
<div style="width:59%; float:right">
```{r bxplot_cor, echo = F, fig.show='hold', warning=FALSE}
show_fig(expr = {
boxplot(cor_dsaeschimann2017 ~ interaction(dsaeschimann2017$p$strain, dsaeschimann2017$p$age), col = transp(1:4), xaxt = "n", ylab = "Spearman correlation",
        xlab = "age", at = seq(1,44, l = 55)[c(T,T,T,T,F)])
axis(side = 1, at = seq(2,42, l = 11), labels = unique(dsaeschimann2017$p$age))
legend(23,.86, fill = transp(1:4), legend = c("let-7", "lin-41", "let-7/lin-41", "N2"),
       bty = "n")
})
```
</div>
</div>
<div style="clear: both;"></div>

###### Code
```{r hm_bxp_code_print, eval = F}
# Heatmap
ord <- order(dsaeschimann2017$p$age)
heatmap(cor_dsaeschimann2017[ord, ord], Colv = NA, Rowv = NA, scale = "none", keep.dendro = F, margins = c(1,1),
        RowSideColors = as.numeric(dsaeschimann2017$p$strain[ord]), labRow = "", labCol = "")

par(xpd = T) # text may have to be tweaked to plot size
mtext(text = unique(dsaeschimann2017$p$age), side = 1, line = 4, at = seq(-.1,1.05, l = 11)) 

# Boxplot
boxplot(cor_dsaeschimann2017 ~ interaction(dsaeschimann2017$p$strain, dsaeschimann2017$p$age), col = 1:4, xaxt = "n", 
        ylab = "Spearman correlation", xlab = "age", at = seq(1,44, l = 55)[c(T,T,T,T,F)])
axis(side = 1, at = seq(2,42, l = 11), labels = unique(dsaeschimann2017$p$age))

legend(23,.86, fill = 1:4, legend = c("let-7", "lin-41", "let-7/lin-41", "N2"), bty = "n")
```

##### {}


### Plotting components
You can also plot components (PCA or ICA) with respect to time, to get an idea of the dynamics.
For PCA, we want to perform a non-scaled, centered PCA. 
Centering must be done gene-wise, not sample-wise (hence the matrix rotation below).

```{r obs_prcomp, eval = gen_figs}
pca_dsaeschimann2017 <- stats::prcomp(t(dsaeschimann2017$g), rank = 25,
                                      center = TRUE, scale = FALSE)
```

##### {.tabset}
###### Plot
```{r plot_pcadsaeschimann2017, echo = F, fig.height=6, fig.width=12}
show_fig(expr = {
  par(mfrow = c(2,4))
  invisible(sapply(seq_len(8), function(i){
    plot(dsaeschimann2017$p$age, pca_dsaeschimann2017$x[,i], lwd = 2, col = dsaeschimann2017$p$strain,
         xlab = "age", ylab = "PC", main = paste0("PC", i))
    sapply(seq_along(levels(dsaeschimann2017$p$strain)), function(l){
      s <- which(dsaeschimann2017$p$strain == levels(dsaeschimann2017$p$strain)[l])
      points(dsaeschimann2017$p$age[s], pca_dsaeschimann2017$x[s,i], col = l, 
             type = 'l', lty = 2)
    })
    # points(ndat$age, pred_dsaeschimann2017_comp[, i], col = "royalblue", type = 'l', lwd = 2)
    if(i == 1)
      legend("topleft", bty = 'n', legend = c("let-7", "lin-41", "let-7/lin-41", "N2"),
             pch = c(rep(1, 4)), lty = c(rep(NA, 4)), col = c(1:4), lwd = 3)
  }))
}, fig.height=6, fig.width=12)
```

###### Code
```{r plot_pcadsaeschimann2017_print, eval = F}
par(mfrow = c(2,4))
invisible(
sapply(seq_len(8), function(i){
  plot(dsaeschimann2017$p$age, pca_dsaeschimann2017$x[,i], lwd = 2, col = dsaeschimann2017$p$strain,
       xlab = "age", ylab = "PC", main = paste0("PC", i))
  
  # connect the dots
  sapply(seq_along(levels(dsaeschimann2017$p$strain)), function(l){
    s <- which(dsaeschimann2017$p$strain == levels(dsaeschimann2017$p$strain)[l])
    points(dsaeschimann2017$p$age[s], pca_dsaeschimann2017$x[s,i], col = l, 
           type = 'l', lty = 2)
  })

  if(i == 1)
    legend("topleft", bty = 'n', legend = c("let-7", "lin-41", "let-7/lin-41", "N2"),
           pch = c(rep(1, 4)), lty = c(rep(NA, 4)), col = c(1:4), lwd = 3)
})
)
```
##### {}

In this data, we see that between different strains, we get very consistent dynamics. 
Also, PC2 and PC3 capture an oscillatory dynamic which is characteristic of the molting processes of *C. elegans* larval development.


### Plotting random genes
Another approach can be to look at a few random genes. You get a first hand look at the noise in your data.

##### {.tabset}
###### Plots
```{r plot_rdgn, echo = F, fig.height=3, fig.width=12}
show_fig(expr = {
  set.seed(10)
  gtp <- sample(nrow(dsaeschimann2017$g), size = 4)
  par(mfrow = c(1,4))
  invisible(sapply(gtp, function(i){
    plot(dsaeschimann2017$p$age, dsaeschimann2017$g[i,], lwd = 2, col = dsaeschimann2017$p$strain,
         xlab = "age", ylab = "GExpr", main = rownames(dsaeschimann2017$g)[i])
    sapply(seq_along(levels(dsaeschimann2017$p$strain)), function(l){
      s <- which(dsaeschimann2017$p$strain == levels(dsaeschimann2017$p$strain)[l])
      points(dsaeschimann2017$p$age[s], dsaeschimann2017$g[i,s], col = l, 
             type = 'l', lty = 2)
    })
    # points(ndat$age, pred_dsaeschimann2017_comp[, i], col = "royalblue", type = 'l', lwd = 2)
    if(i == gtp[4])
      legend("topleft", bty = 'n', legend = c("let-7", "lin-41", "let-7/lin-41", "N2"),
             pch = c(rep(1, 4)), lty = c(rep(NA, 4)), col = c(1:4), lwd = 3)
  }))
}, fig.height=3, fig.width=12)
```

###### Code
```{r plot_rdgn_print, eval = F}
set.seed(10)
gtp <- sample(nrow(dsaeschimann2017$g), size = 4)

par(mfrow = c(1,4))
invisible(
sapply(gtp, function(i){
  plot(dsaeschimann2017$p$age, dsaeschimann2017$g[i,], lwd = 2, col = dsaeschimann2017$p$strain,
       xlab = "age", ylab = "GExpr", main = rownames(dsaeschimann2017$g)[i])
  
  # connect the dots
  sapply(seq_along(levels(dsaeschimann2017$p$strain)), function(l){
    s <- which(dsaeschimann2017$p$strain == levels(dsaeschimann2017$p$strain)[l])
    points(dsaeschimann2017$p$age[s], dsaeschimann2017$g[i,s], col = l, 
           type = 'l', lty = 2)
  })

  if(i == gtp[4])
    legend("topleft", bty = 'n', legend = c("let-7", "lin-41", "let-7/lin-41", "N2"),
           pch = c(rep(1, 4)), lty = c(rep(NA, 4)), col = c(1:4), lwd = 3)
})
)

```

##### {}

<br>
<br>
<br>

# The gene expression interpolation model

To increase the resolution of our time series, we are faced with a very unbalanced regression problem.
We essentially want to predict tens of thousands of dependent variables (genes) with our few independent variables (time, batch, ...).

We refer to the gene expression interpolation model as GEIM in the following text. 


## About the model

The principal strategy we put forward for predicting on such a large scale of output variables, is to interpolate in a dimensionally reduced space. 
We propose to do this on Principal Components or Independant Components ( [Independant Component Analysis](https://en.wikipedia.org/wiki/Independent_component_analysis) ).

Both PCA and ICA perform the same type of linear transformation on the data, they just maximize a different criteria. 
PCA maximizes the variance of each component and ICA their independance. We get the following :

$$
X_{(m\times n)} = G_{(m\times c)}S^{T}_{(n\times c)}
$$
with $X$, the matrix of $m$ genes by $n$ samples, $G$ the gene loadings ($m$ genes by $c$ components) and $S^T$ the sample loadings ($n$ samples by $c$ components). 
$S$ is what's usually looked at when performing a PCA (or ICA) on gene expression data, to look at the samples in the component space. It's what we plotted in the section on observing data, for instance. 

@alter2000singular previously demonstrated that singular value decomposition of gene expression data can be taken as "eigengenes", giving a global picture of the dynamics of gene expression. 
We essentially use the same property for a GEIM.
We build a model on the columns of $S^T$ (eigengenes), predict in the component space, and reconstruct the gene expression data by a matrix product with the gene loadings. 

We've implemented 2 model types : Generalized Additive Models (GAMs, the default) and Generalized Linear Models (GLMs). 
GAMs rely on the `gam()` function of the [`mgcv`](https://cran.r-project.org/web/packages/mgcv/index.html) package, and GLMs on the `glm()` function of the `stats` core package. 

As you'll see in the next section, a standard R formula will be specifed to the model.
This formula can make use of all the tools one can use with `gam()` or `glm()`, most notably the variety of polynomial or smoothing splines implemented through the `s()` function for GAMs. 
With GLMs, you can also use splines from the `splines` core package, such as `ns()` for natural cubic splines.


## The GEIM interface

GEIMs, are built with the `ge_im()` function, which outputs a `geim` object.
This function takes as input 3 key arguments : 

 - `X` : the gene expression matrix of your time series (genes as rows, samples as columns)
 - `p` : a dataframe of pheno data, samples as rows. This should include the age/time variable and any other covariates you want to include in the model (*e.g* batch, strain)
 - `formula` : the model formula. This should be a standard R formula, using terms found in `p`. **It should start with `X ~`**.
 
Another important argument is the number of components used for the interpolation, `nc`.

For example, using the `dsaeschimann2017` dataset we could build the following model.
```{r model_dsaeschimann2017, eval = gen_figs}
m_dsaeschimann2017 <- ge_im(X = dsaeschimann2017$g, p = dsaeschimann2017$p, 
                            formula = "X ~ s(age, bs = 'ts') + strain", nc = 32)
```

Note that a single model formula is specified and applied to all the components, but the models are fitted independantly on each component.

Feel free to have a look at the documentation of the function for additionnal parameters `?ge_im()`.

To get model predictions, you simply use the `predict()` function, like for any standard R model.
<!-- **Note that predictions correspond to a scaled version of `X` because of the dimension reduction procedure.** -->


## Finding the appropriate model and parameters
### Model type
There are 5 types of GEIM you can fit with the `ge_im()` function.

* A GAM on PCA components (`method = "gam", dim_red = "pca"`) (default)
* A GLM on PCA components (`method = "glm", dim_red = "pca"`)
* A GAM on ICA components (`method = "gam", dim_red = "ica"`)
* A GLM on ICA components (`method = "glm", dim_red = "ica"`)
* A gene-by-gene linear model directly on the gene expression matrix (`method = "limma"`)

The default option is a robust choice when applying a smoothing spline to the data.

Using PCA or ICA components yields near-identical results in most scenarios. 
ICA tends to outperform PCA when the data is very noisy. 
This is by design since ICA essentially performs signal extraction.
It is however slower, especially if `nc` is large.

The last option (`"limma"`) corresponds to a solution that makes no effort to reduce the dimensionality of the problem (the `dim_red` and `nc` arguments are ignored). 
As a result, there is no information loss or bias introduced by dimension reduction. 
This approach is however very sensitive to noise.
The model is fit with the `lmFit()` function of the `limma` package (hence the name).


Note that when using GAMs, there is by definition no interaction possible between terms. 
It is possible to include a `by` argument to the `s()` function, but this essentialy corresponds to separate fits on the levels of the specified factor/variable.

### Model performance

One can use a number of criteria to evaluate model performance. 
We provide the `mperf()` function to compute the indices described below by inputing the data and the model predictions. 

In the formulas below, $X$ corresponds to the input gene expression matrix ($m$ genes as rows, $n$ samples as columns), $\hat{X}$ to the model predictions. $x_i$ corresponds to row $i$ of matrix $X$ and $x_i^{(j)}$ to sample $j$ of that row. 
This notation is derived from the general regression problem, where $X^T$ corresponds to the set of $m$ dependant variable to predict.

 - `aCC` : average Correlation Coefficient.
 
$$ 
 aCC = \frac{1}{m}\sum^{m}_{i=1}{CC} = \frac{1}{m}\sum^{m}_{i=1}{\cfrac{\sum^{n}_{j=1}{(x_i^{(j)}-\bar{x}_i)(\hat{x}_i^{(j)}-\bar{\hat{x}}_i)}}{\sqrt{\sum^{n}_{j=1}{(x_i^{(j)}-\bar{x}_i)^2(\hat{x}_i^{(j)}-\bar{\hat{x}}_i)^2}}}}
$$

 - `aRE` : average Relative Error. 
 
$$ 
a\delta = \frac{1}{m}\sum^{m}_{i=1}{\delta} = \frac{1}{m} \sum^{m}_{i=1} \frac{1}{n} \sum^{n}_{j=1} \cfrac{| x_i^{(j)} - \hat{x}_i^{(j)} | }{x_i^{(j)}}
$$

 - `MSE` : Mean Squared Error. 

$$ 
MSE = \frac{1}{m} \sum^{m}_{i=1} \frac{1}{n} \sum^{n}_{j=1} (x_i^{(j)} - \hat{x}_i^{(j)} )^2
$$

 - `aRMSE` : average Root MSE.
 
$$ 
aRMSE = \frac{1}{m}\sum^{m}_{i=1}{RMSE} = \frac{1}{m} \sum^{m}_{i=1} \sqrt{\cfrac{\sum^{n}_{j=1} (x_i^{(j)} - \hat{x}_i^{(j)} )^2}{n}}
$$

Note that these indices are computed and averaged *with respect to variables, not observations*. 
You can either get the overall (averaged) index or the value per gene with the `global` parameter.


```{r mperf_dsaeschimann2017, results='markup', eval = gen_figs}
g_mp <- mperf(dsaeschimann2017$g, predict(m_dsaeschimann2017), is.t = T)
g_mp
#> $aCC
#> [1] 0.7977299
#> 
#> $aRE
#> [1] 0.1301014
#> 
#> $MSE
#> [1] 0.01431891
#> 
#> $aRMSE
#> [1] 0.1196617
ng_mp <- mperf(dsaeschimann2017$g, predict(m_dsaeschimann2017), is.t = T, global = F)
ng_mp <- lapply(ng_mp, na.omit) # remove NAs (eg. 0 variance genes)
ng_mp$aRE <- ng_mp$aRE[ng_mp$aRE < Inf] # remove Inf values (/0)
```

It's possible to check the model performance by looking at the index distributions over all genes, *e.g. :*

##### {.tabset}
###### Plots
```{r bxp_mperf_dsaeschimann2017, echo = F, fig.height=5, fig.width=8}
show_fig(expr = {  
  par(mfrow = c(2,2))
  invisible(sapply(names(ng_mp), function(idx){
    rg <- range(na.omit(ng_mp[[idx]]))
    if(idx == "aCC"){
      pos <- 2
    } else {
      pos <- 4
    }
    d <- density(na.omit(ng_mp[[idx]]), from = rg[1], to = rg[2])
    plot(d, main = paste0(gsub("a", "", idx, fixed = T), " density (", length(ng_mp[[idx]]), " genes)"), xlab = idx, lwd = 2)
    abline(v = g_mp[[idx]], lty = 2, lwd = 2, col = "firebrick")
    text(g_mp[[idx]], .9*max(d$y), pos = pos, labels = idx, font = 2, col = "firebrick")
  }))
}, fig.height=5, fig.width=8)
```

###### Code
```{r bxp_mperf_dsaeschimann2017_print, eval = F}
par(mfrow = c(2,2))
invisible(
sapply(names(ng_mp), function(idx){
  rg <- range(na.omit(ng_mp[[idx]]))
  
  # label position
  if(idx == "aCC"){
    pos <- 2
  } else {
    pos <- 4
  }
  # estimate density curve
  d <- density(na.omit(ng_mp[[idx]]), from = rg[1], to = rg[2])
  
  plot(d, main = paste0(gsub("a", "", idx, fixed = T), " density (", length(ng_mp[[idx]]), " genes)"), 
       xlab = idx, lwd = 2)
  # display global value
  abline(v = g_mp[[idx]], lty = 2, lwd = 2, col = "firebrick")
  text(g_mp[[idx]], .9*max(d$y), pos = pos, labels = idx, font = 2, col = "firebrick")
})
)
```

##### {}


### Number of components 

The number of components to use for the interpolation is by default set to the number of samples.
However, we recommend to set a cutoff on explained variance of PCA components to select it. 
You can do this (on PCA explained variance) even if you choose to use ICA for interpolation.

For example, on the `dsaeschimann2017` dataset, we set the threshold at $99\%$ :

```{r nc_dsaeschimann2017, eval=gen_figs}
nc <- sum(summary(pca_dsaeschimann2017)$importance[3,] < .99) + 1
nc
#> [1] 32
```

Note that this threshold must be set in accordance with the noise in the data. For example, in very noisy data, would you consider that $99\%$ of the variance in the dataset corresponds to meaningful dynamics ?

You can also define `nc` by plotting your components and stopping after the components stop capturing meaningful variation (dynamics) with respect to time/age.

In very noisy dataset, you may have to keep very few components ($<5$) for the interpolation.


### Comparing formulas

Choosing from different splines (and/or parameters) can be done with cross-validation (CV) through the use of the `ge_imCV()` function. 
The function inputs the `X`, `p` and a `formula_list` to test. 
Other parameters on the CV itself can also be given (*e.g.* training set size).

The default training/validation set ratio is `cv.s = 0.8`, so $80\%$ of the data is used to build the model. 
When including (factor) covariates in the model, the training set is built such that all groups are proportionately represented in the training set (based on terms of the first formula in the list).
The number of repeats to do for the CV is defined by `cv.n`.

Note that the model type (GAM/GLM, PCA/ICA) is fixed for all formulas in one call of `ge_imCV()`.

`ge_imCV()` computes the indices of model performance with `mperf()`, excluding `aCC` due to computing time. 
Indices are computed on the validation set (CV Error) *and* on the training set (Model PerFormance).

Below is an example of usage to choose between 4 available GAM smooth terms on the `dsaeschimann2017` GEIM.
```{r include = F, eval = gen_figs}
set.seed(2)
```

```{r cv_dsaeschimann2017, results='markup', eval = gen_figs}
smooth_methods <- c("tp", "ts", "cr", "ps")
flist <- as.list(paste0("X ~ s(age, bs = \'", smooth_methods, "\') + strain"))
flist
#> [[1]]
#> [1] "X ~ s(age, bs = 'tp') + strain"
#> 
#> [[2]]
#> [1] "X ~ s(age, bs = 'ts') + strain"
#> 
#> [[3]]
#> [1] "X ~ s(age, bs = 'cr') + strain"
#> 
#> [[4]]
#> [1] "X ~ s(age, bs = 'ps') + strain"

cv_dsaeschimann2017 <- ge_imCV(X = dsaeschimann2017$g, p = dsaeschimann2017$p, formula_list = flist,
                  cv.n = 20, nc = nc, nb.cores = 3)
#> CV on 4 models. cv.n = 20 | cv.s = 0.8
#> 
#> ...Building training sets
#> ...Setting up cluster
#> ...Running CV
#> ...Cleanup and formatting
```

```{r plot_cv_dsaeschimann2017_show, eval = F}
plot(cv_dsaeschimann2017, names = paste0("bs = ", smooth_methods), outline = F,
     swarmargs = list(cex = .8))
```

```{r plot_cv_dsaeschimann2017, echo = F, fig.width=9, fig.height=8, fig.align='center'}
show_fig(expr = {
  plot(cv_dsaeschimann2017, names = paste0("bs = ", smooth_methods), outline = F,
       swarmargs = list(cex = .8))
}, fig.width=9, fig.height=8)
```

From the plots above, the cubic regression spline (`cr`) seems to be the best-performing choice. 


You can also specify extra spline parameters for a fit. 
With `s()`, you can give the number of knots to use with the `k` parameters. 
By default, the spline is a *penalized spline*, so it will not necessarily use `k` knots, but it will stay around that value. 
In our experience, this is not really necessary as the parameter estimation done with `gam()` is usually sufficient.

To force a spline with `k` knots, you must also set `fx = TRUE` (note this fits a spline of `k` knots on *all* components, whereas the penalized spline will adjust). 
You can look at the `s()` or `choose.k` documentation for further information.

Below is an example with the `dsaeschimann2017` data.

```{r cv_dsaeschimann2017_k, eval = gen_figs}
ks <- c(4,6,8,10)
flistk <- as.list(c(
  "X ~ s(age, bs =  'cr') + strain",
  paste0("X ~ s(age, bs =  'cr', k = ", ks , ") + strain"), 
  paste0("X ~ s(age, bs =  'cr', k = ", ks , ", fx=TRUE) + strain")
  ))
flistk
#> [[1]]
#> [1] "X ~ s(age, bs =  'cr') + strain"
#> 
#> [[2]]
#> [1] "X ~ s(age, bs =  'cr', k = 4) + strain"
#> 
#> [[3]]
#> [1] "X ~ s(age, bs =  'cr', k = 6) + strain"
#> 
#> [[4]]
#> [1] "X ~ s(age, bs =  'cr', k = 8) + strain"
#> 
#> [[5]]
#> [1] "X ~ s(age, bs =  'cr', k = 10) + strain"
#> 
#> [[6]]
#> [1] "X ~ s(age, bs =  'cr', k = 4, fx=TRUE) + strain"
#> 
#> [[7]]
#> [1] "X ~ s(age, bs =  'cr', k = 6, fx=TRUE) + strain"
#> 
#> [[8]]
#> [1] "X ~ s(age, bs =  'cr', k = 8, fx=TRUE) + strain"
#> 
#> [[9]]
#> [1] "X ~ s(age, bs =  'cr', k = 10, fx=TRUE) + strain"

cv_dsaeschimann2017k <- ge_imCV(X = dsaeschimann2017$g, p = dsaeschimann2017$p, formula_list = flistk,
                   cv.n = 20, nc = nc, nb.cores = 3)
#> CV on 9 models. cv.n = 20 | cv.s = 0.8
#> 
#> ...Building training sets
#> ...Setting up cluster
#> ...Running CV
#> ...Cleanup and formatting
```

```{r plot_cv_dsaeschimann2017k, echo = F, fig.width=12, fig.height=9, fig.align='center'}
show_fig(expr = {
  par(mar = c(7,4,3,1))
  plot(cv_dsaeschimann2017k, names = c("na", paste0("k=", ks, rep(c("", ", fx=T"), each = 4))), outline = F,
       col = transp(c("royalblue", rep(c(1, "firebrick"), each = 4))), 
       tcol = c("royalblue", rep(c(1, "firebrick"), each = 4)),
       names.arrange = 5, swarmargs = list(cex = .8))
}, fig.width=12, fig.height=9)
```


## Predicting new timepoints

The entire reason we need GEIMs is to interpolate. 
We want a higher precision time series to stage samples.

To do this, as for any R model, we will use the `predict()` function.
We first need to set up the new data to predict from. 

```{r ndat_mdsaeschimann2017, results='markup', eval = gen_figs}
n.inter <- 100 # nb of new timepoints
newdat <- data.frame(
  age = seq(min(dsaeschimann2017$p$age), max(dsaeschimann2017$p$age), l = n.inter),
  strain = rep("N2", n.inter) # we want to predict as N2 
  )
head(newdat)
#>        age strain
#> 1 18.00000     N2
#> 2 18.20202     N2
#> 3 18.40404     N2
#> 4 18.60606     N2
#> 5 18.80808     N2
#> 6 19.01010     N2

# predict 
pred_m_dsaeschimann2017 <- predict(m_dsaeschimann2017, newdata = newdat)
```

You can choose to output the predictions directly as the full gene expression matrix (default) or as components.
Predictions as components with the `as.c = TRUE` option can be useful when checking the interpolation (see the next section).

```{r pred_mdsaeschimann2017_comp, eval = gen_figs}
pred_m_dsaeschimann2017_comp <- predict(m_dsaeschimann2017, newdata = newdat, as.c = TRUE)
```


## Validating / Checking model predictions

We have built our model and predicted new data, now we can have a look at the interpolation results. 
To do this, one can do two things.

### Checking model predictions against components
Checking model predictions against components allows you to see immediately if some dynamics get mishandled by the model. 

Don't hope for perfect fits ! 
It's perfectly acceptable to have slight offsets. 
You may also notice some noisy components get "flattened", with a null model fitted. 
These have little impact on the results as they usually correspond to a minuscule part of total variance. 
They also sometimes actually get rid of some unwanted variation.
 
On the `dsaeschimann2017` dataset, the predictions of the first few components are plotted below.

##### {.tabset}
###### Plots
```{r plot_pca_dsaeschimann2017, echo = F, fig.width=12, fig.height=6}
show_fig(expr = {
  par(mfrow = c(2,4))
  invisible(sapply(seq_len(8), function(i){
    plot(dsaeschimann2017$p$age, pca_dsaeschimann2017$x[,i], lwd = 2, col = dsaeschimann2017$p$strain,
         xlab = "age", ylab = "PC", main = paste0("PC", i))
    sapply(seq_along(levels(dsaeschimann2017$p$strain)), function(l){
      s <- which(dsaeschimann2017$p$strain == levels(dsaeschimann2017$p$strain)[l])
      points(dsaeschimann2017$p$age[s], pca_dsaeschimann2017$x[s,i], col = l, 
             type = 'l', lty = 2)
    })
    points(newdat$age, pred_m_dsaeschimann2017_comp[, i], col = "royalblue", type = 'l', lwd = 3)
    if(i == 1)
      legend("topleft", bty = 'n', legend = c("let-7", "lin-41", "let-7/lin-41", "N2", "pred"),
             pch = c(rep(1, 4), NA), lty = c(rep(NA, 4), 1), col = c(1:4, "royalblue"), lwd = c(rep(3,4),4))
  }))
}, fig.width=12, fig.height=6)
```

###### Code
```{r plot_pca_dsaeschimann2017_print, eval=F}
par(mfrow = c(2,4))
invisible(
sapply(seq_len(8), function(i){
  plot(dsaeschimann2017$p$age, pca_dsaeschimann2017$x[,i], lwd = 2, col = dsaeschimann2017$p$strain,
       xlab = "age", ylab = "PC", main = paste0("PC", i))
  
  # connect the dots
  sapply(seq_along(levels(dsaeschimann2017$p$strain)), function(l){
    s <- which(dsaeschimann2017$p$strain == levels(dsaeschimann2017$p$strain)[l])
    points(dsaeschimann2017$p$age[s], pca_dsaeschimann2017$x[s,i], col = l, 
           type = 'l', lty = 2)
  })
  
  # add model prediction
  points(newdat$age, pred_m_dsaeschimann2017_comp[, i], col = "royalblue", type = 'l', lwd = 3)
  
  if(i == 1)
    legend("topleft", bty = 'n', legend = c("let-7", "lin-41", "let-7/lin-41", "N2", "pred"),
           pch = c(rep(1, 4), NA), lty = c(rep(NA, 4), 1), col = c(1:4, "royalblue"), lwd = c(rep(3,4),4))
})
)
```
##### {}

 
The interpolation should translates well back on the full expression matrix :

##### {.tabset}
###### Plots
```{r plot_rd_genes_pred, echo = F, fig.height = 3, fig.width=12}
show_fig(expr = {
  par(mfrow = c(1,4))
  invisible(sapply(gtp, function(i){
    plot(dsaeschimann2017$p$age, dsaeschimann2017$g[i,], lwd = 2, col = dsaeschimann2017$p$strain,
         xlab = "age", ylab = "GExpr", main = rownames(dsaeschimann2017$g)[i])
    sapply(seq_along(levels(dsaeschimann2017$p$strain)), function(l){
      s <- which(dsaeschimann2017$p$strain == levels(dsaeschimann2017$p$strain)[l])
      points(dsaeschimann2017$p$age[s], dsaeschimann2017$g[i,s], col = l, 
             type = 'l', lty = 2)
    })
    points(newdat$age, pred_m_dsaeschimann2017[i, ], col = "royalblue", type = 'l', lwd = 3)
    if(i == gtp[4])
      legend("topleft", bty = 'n', legend = c("let-7", "lin-41", "let-7/lin-41", "N2"),
             pch = c(rep(1, 4)), lty = c(rep(NA, 4)), col = c(1:4), lwd = 3)
  }))
}, fig.height = 3, fig.width=12)
```

###### Code
```{r plot_rd_genes_pred_print, eval = F}
par(mfrow = c(1,4))
invisible(
sapply(gtp, function(i){ # gtp is from the earlier gene plots
  plot(dsaeschimann2017$p$age, dsaeschimann2017$g[i,], lwd = 2, col = dsaeschimann2017$p$strain,
       xlab = "age", ylab = "GExpr", main = rownames(dsaeschimann2017$g)[i])
  
  # connect the dots
  sapply(seq_along(levels(dsaeschimann2017$p$strain)), function(l){
    s <- which(dsaeschimann2017$p$strain == levels(dsaeschimann2017$p$strain)[l])
    points(dsaeschimann2017$p$age[s], dsaeschimann2017$g[i,s], col = l, 
           type = 'l', lty = 2)
  })
  
  # add model prediction
  points(newdat$age, pred_m_dsaeschimann2017[i, ], col = "royalblue", type = 'l', lwd = 3)
  
  if(i == gtp[4])
    legend("topleft", bty = 'n', legend = c("let-7", "lin-41", "let-7/lin-41", "N2"),
           pch = c(rep(1, 4)), lty = c(rep(NA, 4)), col = c(1:4), lwd = 3)
})
)
```
##### {}


### Staging samples

Testing your reference on its final purpose is a good practice.

A first test is to stage the samples you used to build the reference on their own interpolated reference.

Finally, the best validation is to stage another time series from the literature on your reference if such data exists.
This provides external validation, confirming the dynamics you interpolated on indeed correspond to development processes and not a specific effect of the dataset (which is unlikely, but not impossible).

We can do this with our example, and the `dshendriks2014` dataset can be used for external validation.

```{r ae_dsaeschimann2017_test_print, eval = F}
# make a 'reference object' 
r_dsaeschimann2017 <- list(interpGE = pred_m_dsaeschimann2017, time.series = newdat$age)

ae_test_dsaeschimann2017 <- ae(dsaeschimann2017$g, r_dsaeschimann2017$interpGE, r_dsaeschimann2017$time.series)
ae_test_dshendriks2014 <- ae(dshendriks2014$g, r_dsaeschimann2017$interpGE, r_dsaeschimann2017$time.series)
```

```{r ae_dsaeschimann2017_test, include = F, eval = gen_figs}
# make a 'reference object' 
r_dsaeschimann2017 <- list(interpGE = pred_m_dsaeschimann2017, time.series = newdat$age)

ae_test_dsaeschimann2017 <- ae(dsaeschimann2017$g, r_dsaeschimann2017$interpGE, r_dsaeschimann2017$time.series, bootstrap.n = 1)
ae_test_dshendriks2014 <- ae(dshendriks2014$g, r_dsaeschimann2017$interpGE, r_dsaeschimann2017$time.series, bootstrap.n = 1)
```

##### {.tabset}
###### Plots
```{r ae_vs_est_plot, echo=F, fig.height=6, fig.width=12}
show_fig(expr = {
  par(mfrow = c(1,2))
  rg <- range(c(ae_test_dsaeschimann2017$age.estimates[,1], dsaeschimann2017$p$age))
  plot(ae_test_dsaeschimann2017$age.estimates[,1]~dsaeschimann2017$p$age, 
       xlab = "Chronological age", ylab = "Estimated age (dsaeschimann2017)", 
       xlim = rg, ylim = rg,
       main = "Chron. vs Estimated ages for dsaeschimann2017\n(on dsaeschimann2017 reference)", lwd = 2, col = factor(dsaeschimann2017$p$strain))
  invisible(sapply(levels(factor(dsaeschimann2017$p$strain)), function(l){
    s <- dsaeschimann2017$p$strain == l
    points(ae_test_dsaeschimann2017$age.estimates[s,1]~dsaeschimann2017$p$age[s], type = 'l', 
           lty = 2, col = which(l==levels(factor(dsaeschimann2017$p$strain))))
  }))
  
  abline(a = 0, b = 1, lty = 3, lwd = 2)
  legend("bottomright", legend = c("let-7", "lin-41", "let-7/lin-41", "N2", "x = y"), 
         lwd=3, col=c(1:4, 1), bty='n', pch = c(1,1,1,1,NA), lty = c(rep(NA, 4), 3))
  
  rg <- range(c(ae_test_dshendriks2014$age.estimates[,1], dshendriks2014$p$age))
  plot(ae_test_dshendriks2014$age.estimates[,1]~dshendriks2014$p$age, 
       xlab = "Chronological age", ylab = "Estimated age (dsaeschimann2017)", 
       xlim = rg, ylim = rg,
       main = "Chron. vs Estimated ages for dshendriks2014\n(on dsaeschimann2017 reference)", lwd = 2)
  points(ae_test_dshendriks2014$age.estimates[,1] ~ dshendriks2014$p$age, type = 'l', lty = 2)
  abline(a = 0, b = 1, lty = 3, lwd = 2)
  
  legend("bottomright", legend = "x = y", lwd=3, col=1, lty = 3, bty='n')
}, fig.height=6, fig.width=12)
```

###### Code
```{r ae_vs_est_plot_print, eval=F}
par(mfrow = c(1,2))
rg <- range(c(ae_test_dsaeschimann2017$age.estimates[,1], dsaeschimann2017$p$age))

# Plot 1
plot(ae_test_dsaeschimann2017$age.estimates[,1]~dsaeschimann2017$p$age, 
     xlab = "Chronological age", ylab = "Estimated age (dsaeschimann2017)", 
     xlim = rg, ylim = rg,
     main = "Chron. vs Estimated ages for dsaeschimann2017\n(on dsaeschimann2017 reference)", lwd = 2, 
     col = factor(dsaeschimann2017$p$strain))
# connect the dots
invisible(sapply(levels(factor(dsaeschimann2017$p$strain)), function(l){
  s <- dsaeschimann2017$p$strain == l
  points(ae_test_dsaeschimann2017$age.estimates[s,1]~dsaeschimann2017$p$age[s], type = 'l', 
         lty = 2, col = which(l==levels(factor(dsaeschimann2017$p$strain))))
}))
abline(a = 0, b = 1, lty = 3, lwd = 2) # x = y

legend("bottomright", legend = c("let-7", "lin-41", "let-7/lin-41", "N2", "x = y"), 
       lwd=3, col=c(1:4, 1), bty='n', pch = c(1,1,1,1,NA), lty = c(rep(NA, 4), 3))


# Plot 2
rg <- range(c(ae_test_dshendriks2014$age.estimates[,1], dshendriks2014$p$age))
plot(ae_test_dshendriks2014$age.estimates[,1]~dshendriks2014$p$age, 
     xlab = "Chronological age", ylab = "Estimated age (dsaeschimann2017)", 
     xlim = rg, ylim = rg,
     main = "Chron. vs Estimated ages for dshendriks2014\n(on dsaeschimann2017 reference)", lwd = 2)
# connect the dots
points(ae_test_dshendriks2014$age.estimates[,1] ~ dshendriks2014$p$age, type = 'l', lty = 2)
abline(a = 0, b = 1, lty = 3, lwd = 2) # x = y

legend("bottomright", legend = "x = y", lwd=3, col=1, lty = 3, bty='n')
```
##### {}
<br>

# Reference-Building examples

Here you will find a few examples of reference building on different organisms.

 - [*C. elegans* larval development](#ex-1) (used in the vignette above)
 - [*D. melanogaster* embryonic development](#ex-2) 
 - [*Danio rerio* embryonic development](#ex-3)

<br>
<br>
<a name="ex-1"></a>


## *C. elegans* larval development
```{r ex_1, child = "ex_1.Rmd"}

```

<br>
<br>
<a name="ex-2"></a>

## *D. melanogaster* embryonic development
```{r ex_2, child = "ex_2.Rmd"}

```


<br>
<br>
<a name="ex-3"></a>

## *Danio rerio* embryonic development
```{r ex_3, child = "ex_3.Rmd"}

```

<a href="#top">Back to top</a>

<hr>

# References